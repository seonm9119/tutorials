{"cells":[{"cell_type":"markdown","source":["#### Setup Codes"],"metadata":{"id":"5TW0q_adF4j9"}},{"cell_type":"code","source":["%load_ext autoreload\n","%autoreload 2"],"metadata":{"id":"eifhyuriF_79"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Google Colab Setup\n","we need to run a few commands to set up our environment on Google Colab. If you are running this notebook on a local machine you can skip this section. Run the following cell to mount your Google Drive."],"metadata":{"id":"DpaWhxTmGaxY"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KXQLqRjBGRbP","executionInfo":{"status":"ok","timestamp":1714454996228,"user_tz":-540,"elapsed":18603,"user":{"displayName":"서나미","userId":"11215307119811085502"}},"outputId":"93deed10-c188-4844-9611-b2d872968730"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import os\n","import sys\n","\n","# TODO: Fill in the Google Drive path where you uploaded the assignment\n","# Example: If you create a 'Test' folder and put all the files under 'example' folder, then 'Test/example'\n","# GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = 'Test/example'\n","GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = 'GIT/tutorials/utils/'\n","GOOGLE_DRIVE_PATH = os.path.join('drive', 'My Drive', GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)\n","sys.path.append(GOOGLE_DRIVE_PATH)\n","\n","print(os.listdir(GOOGLE_DRIVE_PATH))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ut1DWdsPGTsB","executionInfo":{"status":"ok","timestamp":1714454997624,"user_tz":-540,"elapsed":1399,"user":{"displayName":"서나미","userId":"11215307119811085502"}},"outputId":"4c89c900-8c1a-4ab9-e3b7-f78c7642c1cf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['__pycache__', 'for_knn.py', 'linear_classifier.py', 'word_classification.py', 'word2vec.py', 'custom_model_utils', 'image_captioning', 'Convolutional_Neural_Network', '_modules.py', '_utils.py', 'save.py', '_word_processing.py', '_layers.py', 'enc2dec', 'data', '_data.py', 'seq2seq.py', 'image_captioning.py']\n"]}]},{"cell_type":"markdown","source":["##### NLP Setup Codes"],"metadata":{"id":"LPPMUAuxGjTs"}},{"cell_type":"code","source":["!pip install 'portalocker>=2.0.0'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SKrGV_Y2GnVc","executionInfo":{"status":"ok","timestamp":1714455003279,"user_tz":-540,"elapsed":5666,"user":{"displayName":"서나미","userId":"11215307119811085502"}},"outputId":"3ba69c7c-de11-41bb-ed1a-2544f5d33685"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting portalocker>=2.0.0\n","  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n","Installing collected packages: portalocker\n","Successfully installed portalocker-2.8.2\n"]}]},{"cell_type":"code","source":["import torch\n","import torchtext\n","import torchdata\n","\n","print(f'torch version: {torch.__version__}')\n","print(f'torchtext version: {torchtext.__version__}')\n","print(f'torchtext data: {torchdata.__version__}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qXAjbJs8Gqya","executionInfo":{"status":"ok","timestamp":1714455006704,"user_tz":-540,"elapsed":3431,"user":{"displayName":"서나미","userId":"11215307119811085502"}},"outputId":"f6ecf532-9c80-4f00-8f6a-2076fc6f60cb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch version: 2.2.1+cu121\n","torchtext version: 0.17.1+cpu\n","torchtext data: 0.7.1\n"]}]},{"cell_type":"markdown","source":["##### Import Packages"],"metadata":{"id":"71vufT2MGwAu"}},{"cell_type":"code","source":["import random\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","import torch.optim as optim\n","\n","# custom packages\n","import data.word_processing as wp\n","import data.multi30k as multi30k\n","import enc2dec.utils as utils"],"metadata":{"id":"IWtcAnzsGvpg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Multi30k Datasets"],"metadata":{"id":"vAGWbqYgHrLX"}},{"cell_type":"code","source":["!python -m spacy download de_core_news_sm"],"metadata":{"id":"1Mucc09SXdzt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_datasets, val_datasets = multi30k.load_Multi30k(root='.')\n","tokenizer, vocab, ln_idx = multi30k.build_Multi30k_vocab(train_datasets, min_freq=2)"],"metadata":{"id":"I6y4iXm9IQQn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["collate_fn = multi30k.Multi30kCollate(src_transform=wp.build_transform(tokenizer['de'], vocab['de'].token_to_idx),\n","                                      tgt_transform=wp.build_transform(tokenizer['en'], vocab['en'].token_to_idx),\n","                                      PAD_IDX=vocab['en'].stoi['<pad>'],\n","                                      batch_first=True)"],"metadata":{"id":"A26R7z0ICxfd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### seq2seq"],"metadata":{"id":"pYSw73YKS056"}},{"cell_type":"code","source":["class Encoder(nn.Module):\n","    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout, batch_first):\n","        super().__init__()\n","\n","        self.embedding = nn.Embedding(input_dim, emb_dim)\n","        self.lstm = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout, batch_first=batch_first)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, src):\n","\n","        embed = self.embedding(src)\n","        embed = self.dropout(embed)\n","\n","        _, (hidden, cell) = self.lstm(embed)\n","\n","        return hidden, cell"],"metadata":{"id":"zxr1cSYpS6RS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Decoder(nn.Module):\n","    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout, batch_first):\n","        super().__init__()\n","\n","        self.embedding = nn.Embedding(input_dim, emb_dim)\n","        self.lstm = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout, batch_first=batch_first)\n","        self.dropout = nn.Dropout(dropout)\n","        self.fc = nn.Linear(hid_dim, input_dim)\n","\n","    def forward(self, input, prev_h, prev_c):\n","        input = input.unsqueeze(1)\n","        embed = self.embedding(input)\n","        embed = self.dropout(embed)\n","        output, (hidden, cell) = self.lstm(embed, (prev_h, prev_c))\n","        pred = self.fc(output.squeeze(1))\n","\n","\n","        return pred, hidden, cell"],"metadata":{"id":"Ypx748zzS8WU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Seq2Seq(nn.Module):\n","    def __init__(self, enc_in, dec_in, emb_dim, hid_dim,\n","                 n_layers=2, dropout=0.5, teacher_forcing_ratio=0.5,\n","                 BOS_IDX=2, EOS_IDX=3, batch_first=True):\n","        super().__init__()\n","\n","        self.teacher_forcing_ratio = teacher_forcing_ratio\n","        self.BOS_IDX = BOS_IDX\n","        self.EOS_IDX = EOS_IDX\n","\n","        self.encoder = Encoder(input_dim=enc_in,\n","                               emb_dim=emb_dim,\n","                               hid_dim=hid_dim,\n","                               n_layers=n_layers,\n","                               dropout=dropout,\n","                               batch_first=batch_first)\n","\n","        self.decoder = Decoder(input_dim=dec_in,\n","                               emb_dim=emb_dim,\n","                               hid_dim=hid_dim,\n","                               n_layers=n_layers,\n","                               dropout=dropout,\n","                               batch_first=batch_first)\n","\n","\n","    def forward(self, src, tgt):\n","\n","        prev_h, prev_c = self.encoder(src)\n","\n","        output_list = []\n","        input = tgt[:, 0]\n","        for t in range(1, tgt.size(1)):\n","            output, prev_h, prev_c = self.decoder(input, prev_h, prev_c)\n","            output_list.append(output)\n","\n","            # teacher forcing\n","            top1 = output.argmax(dim=1)\n","            input = tgt[:, t] if random.random() < self.teacher_forcing_ratio else top1\n","\n","        return torch.stack(output_list, dim=1)\n","\n","\n","    def inference(self, src, max_length=15):\n","\n","\n","        input = torch.full((src.size(0),), self.BOS_IDX, dtype=torch.int64).to(src.device)\n","        prev_h, prev_c = self.encoder(src)\n","\n","        pred_tokens = []\n","        for _ in range(1, max_length):\n","            output, prev_h, prev_c = self.decoder(input, prev_h, prev_c)\n","\n","            input = output.argmax(dim=1)\n","            pred_tokens.append(input)\n","\n","        return torch.stack(pred_tokens, dim=1)"],"metadata":{"id":"JH_Srb9iS9js"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Sanity check"],"metadata":{"id":"k8G9-yLLUnEw"}},{"cell_type":"code","source":["num_train = len(train_datasets)\n","num_val = len(val_datasets)\n","\n","print(f\"number of train : {num_train}\")\n","print(f\"number of val : {num_val}\")\n","print(f'size of target vocab : {len(vocab[\"en\"])}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZwrnrGhmSILU","executionInfo":{"status":"ok","timestamp":1714456283776,"user_tz":-540,"elapsed":9,"user":{"displayName":"서나미","userId":"11215307119811085502"}},"outputId":"7453f11c-505c-4159-94d9-732ed6766a03"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["number of train : 29001\n","number of val : 1015\n","number of train_sample : 2901\n","number of val_sample : 102\n","size of target vocab : 5893\n"]}]},{"cell_type":"code","source":["data_loaders = {}\n","data_loaders['train'] = DataLoader(train_datasets, batch_size=64, collate_fn=collate_fn, shuffle=True)\n","data_loaders['val'] = DataLoader(val_datasets, batch_size=64, collate_fn=collate_fn)"],"metadata":{"id":"DLlsbnIXRcKX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["criterion = nn.CrossEntropyLoss(ignore_index=vocab['en'].stoi['<pad>'])\n","\n","model = Seq2Seq(enc_in=len(vocab['de']),\n","                dec_in=len(vocab['en']),\n","                emb_dim=256, hid_dim=512,\n","                n_layers=2, dropout=0.5, teacher_forcing_ratio=0.5)\n","\n","\n","src, tgt = next(iter(data_loaders['train']))\n","out = model(src, tgt).transpose(2,1)\n","loss = criterion(out, tgt[:,1:])\n","\n","loss.backward()\n","print(f\"loss : {loss.item()}\")\n","\n","pred = model.inference(src)\n","\n","tokens = vocab['en'].idx_to_sentence(pred[0])\n","print(' '.join(tokens))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N1kfV_JsUo3Z","executionInfo":{"status":"ok","timestamp":1714455050478,"user_tz":-540,"elapsed":10335,"user":{"displayName":"서나미","userId":"11215307119811085502"}},"outputId":"6f1d6d9a-3223-45c4-adba-1f16e5031161"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["loss : 8.682872772216797\n","gated installing voice musician guitar guitar uphill salmon met falling alone furniture miners awe\n"]}]},{"cell_type":"markdown","source":["### Train Net"],"metadata":{"id":"2UGkBxOGhLvW"}},{"cell_type":"code","source":["model = Seq2Seq(enc_in=len(vocab['de']),\n","                dec_in=len(vocab['en']),\n","                emb_dim=256, hid_dim=512,\n","                n_layers=2, dropout=0.5, teacher_forcing_ratio=0.5)\n","\n","optimizer = optim.Adam(model.parameters(), lr=1e-3)\n","criterion = nn.CrossEntropyLoss(ignore_index=vocab['en'].stoi['<pad>'])\n","\n","history = utils.runner(vocab['en'], model, criterion, optimizer, data_loaders, num_epochs=20)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MufqJ9U_hOLj","executionInfo":{"status":"ok","timestamp":1714459573569,"user_tz":-540,"elapsed":1288942,"user":{"displayName":"서나미","userId":"11215307119811085502"}},"outputId":"ad2f113a-bfc8-45ff-95f2-b6a64ab06d38"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train using cuda\n","Epoch [1/20]          time: 0:01:04          train Loss: 4.8136          train BLEU: 0.0076          val Loss: 4.2762          val BLEU: 0.0136          \n","Epoch [2/20]          time: 0:01:04          train Loss: 4.2033          train BLEU: 0.0178          val Loss: 3.8586          val BLEU: 0.0240          \n","Epoch [3/20]          time: 0:01:06          train Loss: 3.8751          train BLEU: 0.0301          val Loss: 3.6618          val BLEU: 0.0347          \n","Epoch [4/20]          time: 0:01:04          train Loss: 3.6463          train BLEU: 0.0444          val Loss: 3.3704          val BLEU: 0.0490          \n","Epoch [5/20]          time: 0:01:05          train Loss: 3.4663          train BLEU: 0.0559          val Loss: 3.3109          val BLEU: 0.0622          \n","Epoch [6/20]          time: 0:01:05          train Loss: 3.3102          train BLEU: 0.0673          val Loss: 3.2067          val BLEU: 0.0772          \n","Epoch [7/20]          time: 0:01:03          train Loss: 3.1889          train BLEU: 0.0766          val Loss: 3.1401          val BLEU: 0.0930          \n","Epoch [8/20]          time: 0:01:03          train Loss: 3.0865          train BLEU: 0.0852          val Loss: 3.0469          val BLEU: 0.0891          \n","Epoch [9/20]          time: 0:01:03          train Loss: 2.9893          train BLEU: 0.0926          val Loss: 2.9956          val BLEU: 0.0993          \n","Epoch [10/20]          time: 0:01:04          train Loss: 2.8911          train BLEU: 0.1004          val Loss: 3.0263          val BLEU: 0.1060          \n","Epoch [11/20]          time: 0:01:03          train Loss: 2.8106          train BLEU: 0.1085          val Loss: 2.9444          val BLEU: 0.1087          \n","Epoch [12/20]          time: 0:01:05          train Loss: 2.7337          train BLEU: 0.1137          val Loss: 2.9972          val BLEU: 0.1150          \n","Epoch [13/20]          time: 0:01:04          train Loss: 2.6741          train BLEU: 0.1202          val Loss: 2.9260          val BLEU: 0.1179          \n","Epoch [14/20]          time: 0:01:04          train Loss: 2.6001          train BLEU: 0.1276          val Loss: 2.9054          val BLEU: 0.1156          \n","Epoch [15/20]          time: 0:01:05          train Loss: 2.5395          train BLEU: 0.1329          val Loss: 2.8751          val BLEU: 0.1198          \n","Epoch [16/20]          time: 0:01:03          train Loss: 2.4876          train BLEU: 0.1387          val Loss: 2.8978          val BLEU: 0.1247          \n","Epoch [17/20]          time: 0:01:03          train Loss: 2.4327          train BLEU: 0.1460          val Loss: 2.8793          val BLEU: 0.1295          \n","Epoch [18/20]          time: 0:01:03          train Loss: 2.3573          train BLEU: 0.1542          val Loss: 2.9363          val BLEU: 0.1291          \n","Epoch [19/20]          time: 0:01:04          train Loss: 2.3221          train BLEU: 0.1594          val Loss: 2.9132          val BLEU: 0.1360          \n","Epoch [20/20]          time: 0:01:03          train Loss: 2.2611          train BLEU: 0.1658          val Loss: 2.9045          val BLEU: 0.1377          \n","\n","Toral Training Time: 0:21:28\n","Finished Training\n"]}]},{"cell_type":"code","source":["torch.save(model.state_dict(), \"seq2seq.pth\")"],"metadata":{"id":"L8s5mikpkPDH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = Seq2Seq(enc_in=len(vocab['de']),\n","                dec_in=len(vocab['en']),\n","                emb_dim=256, hid_dim=512,\n","                n_layers=2, dropout=0.5, teacher_forcing_ratio=0.5)\n","\n","model.load_state_dict(torch.load(\"seq2seq.pth\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mwr1oS9Vrx7A","executionInfo":{"status":"ok","timestamp":1714459645840,"user_tz":-540,"elapsed":318,"user":{"displayName":"서나미","userId":"11215307119811085502"}},"outputId":"941fc74f-5a63-40d1-81a5-3098c0c40cdd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":55}]},{"cell_type":"code","source":["src, tgt = next(iter(data_loaders['val']))\n","pred = model.inference(src)\n","\n","idx = random.randint(0, src.size(0))\n","\n","infer_sentence = vocab['en'].idx_to_sentence(pred[idx])\n","gt_sentence = vocab['en'].idx_to_sentence(tgt[idx])\n","src_sentence = vocab['de'].idx_to_sentence(src[idx])\n","\n","print(f\"src sentence : {src_sentence}\")\n","print(f\"gt sentence : {gt_sentence}\")\n","print(f\"infer sentence : {infer_sentence}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sgYqs6m9m0ii","executionInfo":{"status":"ok","timestamp":1714459772066,"user_tz":-540,"elapsed":866,"user":{"displayName":"서나미","userId":"11215307119811085502"}},"outputId":"7520ab3f-aa17-49a8-e4cd-e14bb3435029"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["src sentence : ['eine', 'frau', 'mit', 'pinkfarbener', 'tasche', 'sitzt', 'auf', 'einer', 'bank', '.']\n","gt sentence : ['a', 'woman', 'with', 'a', 'pink', 'purse', 'is', 'sitting', 'on', 'a', 'bench', '.']\n","infer sentence : ['a', 'woman', 'with', 'a', 'hat', 'is', 'sitting', 'on', 'a', 'bench', 'bench', '.']\n"]}]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.16"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}