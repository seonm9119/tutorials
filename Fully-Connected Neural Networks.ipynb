{"cells":[{"cell_type":"markdown","source":["## Setup Codes"],"metadata":{"id":"Yd9Rx0PI1rhC"}},{"cell_type":"markdown","source":["### Google Colab Setup\n","\n","we need to run a few commands to set up our environment on Google Colab. If you are running this notebook on a local machine you can skip this section. Run the following cell to mount your Google Drive."],"metadata":{"id":"D1maK9s1Q7IJ"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"Nw-zWJ0eQ695","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713067579759,"user_tz":-540,"elapsed":2482,"user":{"displayName":"서나미","userId":"11215307119811085502"}},"outputId":"015e52a5-5c67-4cf9-e0f0-9839492e20b4"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["Now recall the path in your Google Drive where you uploaded this notebook, fill it in below."],"metadata":{"id":"JI01N8HEQ_X8"}},{"cell_type":"code","source":["import os\n","import sys\n","\n","# TODO: Fill in the Google Drive path where you uploaded the assignment\n","# Example: If you create a 'Test' folder and put all the files under 'example' folder, then 'Test/example'\n","# GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = 'Test/example'\n","GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = 'GIT/tutorials/utils/custom_model_utils'\n","GOOGLE_DRIVE_PATH = os.path.join('drive', 'My Drive', GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)\n","sys.path.append(GOOGLE_DRIVE_PATH)\n","\n","print(os.listdir(GOOGLE_DRIVE_PATH))"],"metadata":{"id":"TYcL2cauRAyY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713067579760,"user_tz":-540,"elapsed":14,"user":{"displayName":"서나미","userId":"11215307119811085502"}},"outputId":"02f50707-20e8-4a7f-ed3a-8c4169fbf4dd"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["['__pycache__', 'optimizers.py', 'losses.py', 'modules.py', 'activations.py', 'models.py', 'data.py', 'utils.py']\n"]}]},{"cell_type":"markdown","source":["### Setup Code\n","\n","Run some setup code for this notebook: Import some useful packages"],"metadata":{"id":"KHPePlLaEGEQ"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","# custom utils\n","import utils\n","import data\n","import modules\n","\n","torch.manual_seed(42)\n","torch.cuda.manual_seed_all(42)\n","\n","input_dim = 3 * 32 * 32\n","num_classes = 10"],"metadata":{"id":"bHuSxLTr-Jxs","executionInfo":{"status":"ok","timestamp":1713067589327,"user_tz":-540,"elapsed":9573,"user":{"displayName":"서나미","userId":"11215307119811085502"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["### Load the CIFAR-10 dataset\n"," The utility function eecs598.data.preprocess_cifar10() returns the entire CIFAR-10 dataset as a set of six Torch tensors while also preprocessing the RGB images:"],"metadata":{"id":"PbsSrAYiu3rx"}},{"cell_type":"code","source":["dset_train, dset_val, dset_test = data.load_cifar10(val_ratio=0.2)\n","\n","train_loader = torch.utils.data.DataLoader(dset_train, batch_size=64, shuffle=True)\n","val_loader = torch.utils.data.DataLoader(dset_val, batch_size=64, shuffle=True)\n","test_loader = torch.utils.data.DataLoader(dset_test, batch_size=64, shuffle=False)\n","\n","\n","data_loaders = {}\n","data_loaders['train'] = train_loader\n","data_loaders['val'] = val_loader\n","data_loaders['test'] = test_loader"],"metadata":{"id":"soruam8eu4Nj","executionInfo":{"status":"ok","timestamp":1713067591385,"user_tz":-540,"elapsed":2090,"user":{"displayName":"서나미","userId":"11215307119811085502"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["## Fully-connected neural networks\n","\n","we want to build networks using a more modular design so that we can implement different layer types in isolation and then snap them together into models with different architectures.\n","\n","In this exercise we will implement fully-connected networks using a more modular approach. For each layer we will implement a `forward` and a `backward` function. The `forward` function will receive inputs, weights, and other parameters and will return an output. The `backward` function will receive upstream derivatives, and will return gradients with respect to the inputs and weights.\n","\n","After implementing a bunch of layers this way, we will be able to easily combine them to build classifiers with different architectures."],"metadata":{"id":"CIzVpbdpQVWX"}},{"cell_type":"markdown","source":["## torch.autograd.Function\n","\n","Machine Learning에 대해 배울때, forward()와 backward()에 대해 한 번쯤은 들어봤을 것입니다. 그러나 실제 PyTorch로 모델을 설계할 때, 실제로 backward()를 직접 구현한 경험이 없을 것이다. PyTorch는 `autograd` 기능을 제공하여 사용자가 직접 gradient를 계산할 필요가 없게 설계되어있기 때문이다.\n","\n","해당 튜토리얼에서는 모델의 작동방식을 자세히 살펴보기 위해 `torch.autograd.Function`을 사용하여 `backward`를 직접 구현한다. 이러한 설계를 통해 PyTorch의 내부 작동 구조가 어떠한 방식으로 실행되는지를 조금이나마 이해 할 수 있도록 모델을 설계하였다.\n","\n",">  `torch.autograd.Function`에 대한 자세한 내용은 [여기](https://pytorch.org/docs/stable/notes/extending.html#extending-autograd)를 참조하세요."],"metadata":{"id":"77mhhq1urIfk"}},{"cell_type":"markdown","source":["### Linear layer"],"metadata":{"id":"QYDOmCB-v5k4"}},{"cell_type":"code","source":["class Linear(nn.Module):\n","  def __init__(self, input_dim, output_dim):\n","    super().__init__()\n","\n","    self.W = nn.Parameter(modules.xavier_init(input_dim, output_dim))\n","    self.b = nn.Parameter(torch.zeros(output_dim))\n","\n","  def forward(self, x):\n","    return LinearFunction.apply(x, self.W.to(x.device), self.b.to(x.device))"],"metadata":{"id":"1nKeGczrwCaX","executionInfo":{"status":"ok","timestamp":1713067591387,"user_tz":-540,"elapsed":16,"user":{"displayName":"서나미","userId":"11215307119811085502"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["class LinearFunction(torch.autograd.Function):\n","    @staticmethod\n","    def forward(ctx, input, weight, bias):\n","        ctx.save_for_backward(input, weight, bias)\n","        return torch.matmul(input, weight) + bias\n","\n","    @staticmethod\n","    def backward(ctx, grad_output):\n","        input, weight, bias = ctx.saved_tensors\n","\n","        dx = torch.matmul(grad_output, weight.T)\n","        dw = torch.matmul(input.T, grad_output)\n","        db = grad_output.sum(0)\n","\n","        return dx, dw, db"],"metadata":{"id":"USs52TGXwDRu","executionInfo":{"status":"ok","timestamp":1713067591387,"user_tz":-540,"elapsed":15,"user":{"displayName":"서나미","userId":"11215307119811085502"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["### Multilayer network\n","Next you will implement a fully-connected network with an arbitrary number of hidden layers."],"metadata":{"id":"Qkxh2iTKxY1Z"}},{"cell_type":"code","source":["class FullyConnectedNet(nn.Module):\n","  def __init__(self, input_dim, hidden_dims, num_classes):\n","    super().__init__()\n","\n","    self.layers = nn.ModuleList()\n","\n","    if isinstance(hidden_dims, int):\n","      hidden_dims = [hidden_dims]\n","\n","    in_dim = input_dim\n","    for out_dim in hidden_dims:\n","      self.layers.append(Linear(in_dim, out_dim))\n","      self.layers.append(nn.ReLU())\n","      in_dim = out_dim\n","\n","    self.output_layer = Linear(in_dim, num_classes)\n","\n","  def forward(self, x):\n","\n","    for layer in self.layers:\n","      x = layer(x)\n","\n","    output = self.output_layer(x)\n","\n","    return output"],"metadata":{"id":"s4G3H4s-xjcv","executionInfo":{"status":"ok","timestamp":1713067591388,"user_tz":-540,"elapsed":15,"user":{"displayName":"서나미","userId":"11215307119811085502"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["# Train"],"metadata":{"id":"MWt8sng1CVXX"}},{"cell_type":"code","source":["model = FullyConnectedNet(input_dim, [64, 128], num_classes)\n","utils.summary(model, (1,input_dim))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ef68hZ64Al1V","executionInfo":{"status":"ok","timestamp":1713067591388,"user_tz":-540,"elapsed":15,"user":{"displayName":"서나미","userId":"11215307119811085502"}},"outputId":"e64df3e4-e0f6-42aa-dc9e-2ca6acad63ee"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["=================================================================\n","Layer (type)                Output Shape         Param #\n","=================================================================\n","Linear()                    (1, 64)                  196,672\n","ReLU()                      (1, 64)                        0\n","Linear()                    (1, 128)                   8,320\n","ReLU()                      (1, 128)                       0\n","output_layer                (1, 10)                    1,290\n","=================================================================\n","Total params: 206,282\n","=================================================================\n"]}]},{"cell_type":"code","source":["criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.001)\n","\n","history = utils.runner(model, criterion, optimizer, data_loaders, num_epochs=10, msg=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CwMmq5ubnmZB","executionInfo":{"status":"ok","timestamp":1713067757074,"user_tz":-540,"elapsed":165698,"user":{"displayName":"서나미","userId":"11215307119811085502"}},"outputId":"08911da4-45dd-4675-9626-ede3394b99f0"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Train using cpu\n","Epoch [1/10]          train Loss: 2.2202          train ACC: 18.67%          val Loss: 2.1218          val ACC: 25.65%\n","Epoch [2/10]          train Loss: 2.0633          train ACC: 27.99%          val Loss: 2.0142          val ACC: 29.73%\n","Epoch [3/10]          train Loss: 1.9749          train ACC: 31.06%          val Loss: 1.9417          val ACC: 32.22%\n","Epoch [4/10]          train Loss: 1.9128          train ACC: 33.04%          val Loss: 1.8891          val ACC: 33.87%\n","Epoch [5/10]          train Loss: 1.8668          train ACC: 34.66%          val Loss: 1.8494          val ACC: 34.99%\n","Epoch [6/10]          train Loss: 1.8310          train ACC: 35.93%          val Loss: 1.8187          val ACC: 36.17%\n","Epoch [7/10]          train Loss: 1.8016          train ACC: 37.13%          val Loss: 1.7940          val ACC: 37.09%\n","Epoch [8/10]          train Loss: 1.7766          train ACC: 37.88%          val Loss: 1.7711          val ACC: 37.95%\n","Epoch [9/10]          train Loss: 1.7547          train ACC: 38.76%          val Loss: 1.7509          val ACC: 38.25%\n","Epoch [10/10]          train Loss: 1.7354          train ACC: 39.48%          val Loss: 1.7340          val ACC: 38.96%\n","Finished Training\n","Accuracy of the network on the 157 test images: 39.93%\n"]}]}],"metadata":{"colab":{"provenance":[],"collapsed_sections":["D1maK9s1Q7IJ"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}