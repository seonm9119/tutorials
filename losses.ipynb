{"cells":[{"cell_type":"code","source":["%load_ext autoreload\n","%autoreload 2"],"metadata":{"id":"GcedSiTYE6ip","executionInfo":{"status":"ok","timestamp":1713176996750,"user_tz":-540,"elapsed":9,"user":{"displayName":"서나미","userId":"11215307119811085502"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["### Google Colab Setup\n","\n","we need to run a few commands to set up our environment on Google Colab. If you are running this notebook on a local machine you can skip this section. Run the following cell to mount your Google Drive."],"metadata":{"id":"D1maK9s1Q7IJ"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"Nw-zWJ0eQ695","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713177035246,"user_tz":-540,"elapsed":19042,"user":{"displayName":"서나미","userId":"11215307119811085502"}},"outputId":"9beaecde-e1c0-4449-b69b-ca912864a0ff"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["Now recall the path in your Google Drive where you uploaded this notebook, fill it in below."],"metadata":{"id":"JI01N8HEQ_X8"}},{"cell_type":"code","source":["import os\n","import sys\n","\n","# TODO: Fill in the Google Drive path where you uploaded the assignment\n","# Example: If you create a 'Test' folder and put all the files under 'example' folder, then 'Test/example'\n","# GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = 'Test/example'\n","GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = None\n","GOOGLE_DRIVE_PATH = os.path.join('drive', 'My Drive', GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)\n","sys.path.append(GOOGLE_DRIVE_PATH)\n","\n","print(os.listdir(GOOGLE_DRIVE_PATH))"],"metadata":{"id":"TYcL2cauRAyY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713177036081,"user_tz":-540,"elapsed":840,"user":{"displayName":"서나미","userId":"11215307119811085502"}},"outputId":"74090eb8-8c52-4a0b-af78-b1bc5454e5db"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["['__pycache__', 'optimizers.py', 'losses.py', 'activations.py', 'models.py', 'data.py', 'utils.py', 'modules.py']\n"]}]},{"cell_type":"markdown","source":["### Setting"],"metadata":{"id":"KHPePlLaEGEQ"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","# custom utils\n","import modules\n","import activations\n","import losses\n","import optimizers\n","import utils\n","import models\n","import data\n","\n","torch.manual_seed(42)\n","torch.cuda.manual_seed_all(42)"],"metadata":{"id":"bHuSxLTr-Jxs","executionInfo":{"status":"ok","timestamp":1713177164560,"user_tz":-540,"elapsed":3590,"user":{"displayName":"서나미","userId":"11215307119811085502"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["## Multi-Class Support Vector Machin Loss\n","\n","![](https://cs231n.github.io/assets/margin.jpg)\n","\n","\n","> The Multiclass Support Vector Machine **\"wants\"** the score of the correct class to be higher than all other scores by at least a margin of $\\Delta$. If any class has a score inside the red region (or higher), then there will be accumulated loss. Otherwise the loss will be zero."],"metadata":{"id":"lWnkDsu6wsNS"}},{"cell_type":"markdown","source":["\n","\n","\n","\n","\n","Multi-Class SVM Loss의 수식은 아래와 같다.\n","$$\n","\\begin{aligned}\n","L_i & =\\sum_{j \\neq y_i} \\begin{cases}s_j-s_{y_i}+\\Delta & \\text { if } s_j-s_{y_i}+\\Delta \\geq 0 \\\\\\\\\n","0 & \\text { otherwise }\\end{cases} \\\\\\\\\n","& =\\sum_{j \\neq y_i} \\max \\left(0, s_j-s_{y_i}+\\Delta\\right)\n","\\end{aligned}\n","$$\n"],"metadata":{"id":"NNaNWYkAaQAd"}},{"cell_type":"markdown","source":["Multi-Class SVM Loss 의 도함수는 아래와 같다.\n","\n","$$\\begin{equation}\n","\\frac{\\partial L_i}{\\partial s_k}= \\begin{cases} 1\\left(s_k-s_{y_i}+\\Delta>0\\right) & \\text { if } k \\neq y_i \\\\\\\\ -\\sum_{j\\neq{y_i}} 1\\left(s_j-s_{y_i}+\\Delta>0\\right) & \\text { otherwise }\\end{cases}\n","\\end{equation}$$"],"metadata":{"id":"4zxPocsGhLzf"}},{"cell_type":"code","source":["class MulticlassSVMLoss(torch.autograd.Function):\n","\n","    @staticmethod\n","    def forward(ctx, scores, y_true):\n","\n","        # equation 1. calculate loss\n","        correct_class_scores = scores[range(scores.shape[0]), y_true].unsqueeze(-1)\n","        margins = scores - correct_class_scores + 1\n","        margins[range(scores.shape[0]), y_true] = 0\n","\n","        margins = margins.relu()\n","        ctx.save_for_backward(scores, y_true, margins)\n","\n","        loss = margins.sum(dim=1).mean()\n","        return loss\n","\n","    @staticmethod\n","    def backward(ctx, grad_output):\n","        scores, y_true, margins = ctx.saved_tensors\n","\n","        # equation 2. calculate derivative\n","        ds = torch.zeros_like(scores)\n","        ds[margins > 0] = 1\n","        ds[range(scores.shape[0]), y_true] -= torch.sum(ds, dim=1)\n","\n","        ds /= ds.shape[0]\n","        return ds, None"],"metadata":{"id":"ynLa48xceY1N","executionInfo":{"status":"ok","timestamp":1713177047070,"user_tz":-540,"elapsed":261,"user":{"displayName":"서나미","userId":"11215307119811085502"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["## Softmax Loss\n","\n","\n","\n","\n","\n","Softmax Loss의 수식은 아래와 같다.\n","$$\\begin{aligned}\n","L_i&=-\\log\\frac{e^{s_{y_i}}}{\\sum_j{e^{s_j}}}\\\\\\\\\n","&=-s_{y_i}+\\log\\sum_j{e^{s_j}}\n","\\end{aligned}$$"],"metadata":{"id":"ziErzbSdg03b"}},{"cell_type":"markdown","source":["Softmax Loss 의 도함수는 아래와 같다.\n","> $\\text{softmax}(z)_i=\\frac{e^{z_i}}{\\sum_j{e^{z_j}}}$\n","\n","$$\\begin{aligned}\n","\\frac{\\partial L_i}{\\partial s_k}&=\n","\\begin{cases} \\frac{e^{s_{k}}}{\\sum_j{e^{s_j}}} & \\text { if } k \\neq y_i \\\\\\\\ -1 + \\frac{e^{s_{k}}}{\\sum_j{e^{s_j}}} & \\text { otherwise }\\end{cases}\\\\\\\\\n","&=\\begin{cases} \\text{softmax}(s)_k & \\text { if } k \\neq y_i \\\\\\\\ \\text{softmax}(s)_k-1 & \\text { otherwise }\\end{cases}\n","\\end{aligned}$$\n","\n","\n","\n","\n"],"metadata":{"id":"HAuDPqLthUNi"}},{"cell_type":"code","source":["class SoftmaxLoss(torch.autograd.Function):\n","\n","    @staticmethod\n","    def forward(ctx, scores, y_true):\n","\n","        # equation 1. calculate loss\n","        scores -= scores.max(dim=1, keepdim=True).values\n","        log_softmax = scores - scores.logsumexp(dim=1, keepdim=True)\n","        ctx.save_for_backward(scores, y_true, log_softmax)\n","\n","        loss = -log_softmax[range(log_softmax.shape[0]), y_true]\n","        return loss.mean()\n","\n","    @staticmethod\n","    def backward(ctx, grad_output):\n","        scores, y_true, log_softmax = ctx.saved_tensors\n","\n","        # equation 2. calculate derivative\n","        ds = log_softmax.exp()\n","        ds[range(ds.shape[0]), y_true] -= 1\n","        ds /= ds.shape[0]\n","\n","        return ds, None"],"metadata":{"id":"8INV_0zFhYcx","executionInfo":{"status":"ok","timestamp":1713177050550,"user_tz":-540,"elapsed":376,"user":{"displayName":"서나미","userId":"11215307119811085502"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["## Cross-Entropy Loss\n","\n","> **Definition** : $$\\begin{equation}\n","H(P,Q) = -\\sum_{y} P(y)\\cdot\\log{Q(y)}\n","\\end{equation}$$"],"metadata":{"id":"NQ8V5Jb9hnAF"}},{"cell_type":"markdown","source":["Classification 문제에서, Cross-Entropy를 적용하게 될 경우,\n","일반적으로 Q(y)는 softmax function을 사용하여 확률분포생성하며, P(y)는 label의 원핫벡터가 된다. 즉, 정답클랙스일 경우 P(y)는 1이 되며 아닐 경우 0의 값을 가진다. 이를 수식으로 나타내면 아래와 같다."],"metadata":{"id":"ytcCzVRMbD_C"}},{"cell_type":"markdown","source":["\n","> $\\begin{aligned}\n","&P(y) = \\begin{cases} 0 & \\text { if } y \\neq y_i \\\\ 1 & \\text { otherwise }\\end {cases}\\\\\\\\\n","&Q(y) = \\text{softmax}(s)_y\\\\\\\\\n","\\end{aligned}$"],"metadata":{"id":"s6KgzuBWa_Av"}},{"cell_type":"markdown","source":["\n","\n","\n","\n","\n","\n","전체식을 다시 나타내면,\n","\n","$$\\begin{aligned}\n","L_i &=\\sum_{y} P(y)\\cdot\\text{Softmax Loss}(s)_y\\\\\n","&= 1\\cdot\\text{Softmax Loss}(s)_{y_i}\n","\\end{aligned}$$\n","\n","\n"],"metadata":{"id":"xej2vXTpM4UU"}},{"cell_type":"code","source":["class CrossEntropyLoss(torch.autograd.Function):\n","\n","    @staticmethod\n","    def forward(ctx, scores, y_true):\n","\n","        # Calculate Softmax\n","        scores -= scores.max(dim=1, keepdim=True).values\n","        log_softmax = scores - scores.logsumexp(dim=1, keepdim=True)\n","        one_hot_vec = torch.nn.functional.one_hot(y_true, scores.shape[1])\n","\n","        ctx.save_for_backward(scores, log_softmax, one_hot_vec)\n","\n","        loss = -(one_hot_vec * log_softmax).sum(dim=1)\n","        return loss.mean()\n","\n","    @staticmethod\n","    def backward(ctx, grad_output):\n","        scores, log_softmax, one_hot_vec = ctx.saved_tensors\n","\n","        ds = log_softmax.exp() - one_hot_vec\n","        ds /= ds.shape[0]\n","\n","        return ds, None"],"metadata":{"id":"cSzY-D5GhrD9","executionInfo":{"status":"ok","timestamp":1713177053479,"user_tz":-540,"elapsed":6,"user":{"displayName":"서나미","userId":"11215307119811085502"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["### Kullback-Leibler divergence Loss\n","\n","\n","\n","> **Definition** : $$\\begin{aligned}\n","D_{KL}(P||Q) &= H(P,Q)-H(P)\\\\\\\\\n","&= \\sum_{y} P(y)\\cdot\\log{P(y)} - P(y)\\cdot\\log{Q(y)}\\\\\n","&= \\sum_{y} P(y)\\cdot\\log{\\frac{P(y)}{Q(y)}}\n","\\end{aligned}$$\n","\n"],"metadata":{"id":"Y5XexQt1h5vL"}},{"cell_type":"code","source":["class KLdivergenceLoss(torch.autograd.Function):\n","\n","    @staticmethod\n","    def forward(ctx, scores, y_true):\n","\n","        # Calculate Softmax\n","        scores -= scores.max(dim=1, keepdim=True).values\n","        log_softmax = scores - scores.logsumexp(dim=1, keepdim=True)\n","\n","\n","        one_hot_vec = torch.nn.functional.one_hot(y_true, scores.shape[1])\n","        log_p = one_hot_vec - one_hot_vec.logsumexp(dim=1, keepdim=True)\n","\n","        ctx.save_for_backward(scores, log_softmax, log_p)\n","\n","        loss = (one_hot_vec * (log_p - log_softmax)).sum(dim=1)\n","        return loss.mean()\n","\n","    @staticmethod\n","    def backward(ctx, grad_output):\n","        scores, log_softmax, log_p = ctx.saved_tensors\n","\n","        ds = log_softmax.exp() - log_p.exp()\n","        ds /= ds.shape[0]\n","\n","        return ds, None"],"metadata":{"id":"ZlcrFSPviJjx","executionInfo":{"status":"ok","timestamp":1713177057802,"user_tz":-540,"elapsed":518,"user":{"displayName":"서나미","userId":"11215307119811085502"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["## Sanity Check"],"metadata":{"id":"PmvIgmntviWP"}},{"cell_type":"code","source":["input_dim = 3 * 32 * 32\n","num_classes = 10\n","\n","dset_train, dset_val, dset_test = data.load_cifar10(val_ratio=0.2)\n","\n","data_loaders = {}\n","data_loaders['train'] = torch.utils.data.DataLoader(dset_train, batch_size=64, shuffle=True)\n","data_loaders['val'] = torch.utils.data.DataLoader(dset_val, batch_size=64, shuffle=True)\n","data_loaders['test'] = torch.utils.data.DataLoader(dset_test, batch_size=64, shuffle=False)\n","\n","\n","from torchsummary import summary\n","model = models.MultiLayerNet(input_dim, 128, num_classes)\n","summary(model, input_size=(input_dim,))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jK4DIip5vkim","executionInfo":{"status":"ok","timestamp":1713177457233,"user_tz":-540,"elapsed":2209,"user":{"displayName":"서나미","userId":"11215307119811085502"}},"outputId":"0003a35e-a4c3-46a8-cade-e8d886ca978c"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Linear-1                  [-1, 128]         393,344\n","              ReLU-2                  [-1, 128]               0\n","            Linear-3                   [-1, 10]           1,290\n","================================================================\n","Total params: 394,634\n","Trainable params: 394,634\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.01\n","Forward/backward pass size (MB): 0.00\n","Params size (MB): 1.51\n","Estimated Total Size (MB): 1.52\n","----------------------------------------------------------------\n"]}]},{"cell_type":"code","source":["criterions = {'PyTorch Cross-Entropy Loss': nn.CrossEntropyLoss(),\n","              'Multi-classSVM Loss' : MulticlassSVMLoss.apply,\n","              'Softmax Loss' : SoftmaxLoss.apply,\n","              'CrossEntropy Loss' : CrossEntropyLoss.apply,\n","              'KLdivergence Loss' : KLdivergenceLoss.apply}\n","\n","\n","for key, loss_f in criterions.items():\n","  print(f\"{key}\\n\")\n","  model = models.MultiLayerNet(input_dim, 128, num_classes)\n","  optimizer = optim.SGD(model.parameters(), lr=0.001)\n","  history = utils.runner(model, loss_f, optimizer, data_loaders, num_epochs=10, msg=False)\n","  print('===========================\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KFYbDttDwVZz","executionInfo":{"status":"ok","timestamp":1713178964526,"user_tz":-540,"elapsed":987456,"user":{"displayName":"서나미","userId":"11215307119811085502"}},"outputId":"9d9455b9-bdd8-463a-8493-edde782ec09e"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["PyTorch Cross-Entropy Loss\n","\n","Train using cpu\n","Finished Training\n","Accuracy of the network on the 157 test images: 38.85%\n","===========================\n","\n","Multi-classSVM Loss\n","\n","Train using cpu\n","Finished Training\n","Accuracy of the network on the 157 test images: 47.58%\n","===========================\n","\n","Softmax Loss\n","\n","Train using cpu\n","Finished Training\n","Accuracy of the network on the 157 test images: 38.75%\n","===========================\n","\n","CrossEntropy Loss\n","\n","Train using cpu\n","Finished Training\n","Accuracy of the network on the 157 test images: 38.87%\n","===========================\n","\n","KLdivergence Loss\n","\n","Train using cpu\n","Finished Training\n","Accuracy of the network on the 157 test images: 31.80%\n","===========================\n","\n"]}]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}